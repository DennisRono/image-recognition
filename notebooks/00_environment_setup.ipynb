{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7057c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_packages():\n",
    "    \"\"\"Install required packages for multimodal AI research\"\"\"\n",
    "    packages = [\n",
    "        \"torch torchvision torchaudio\",\n",
    "        \"transformers datasets\",\n",
    "        \"opencv-python librosa\",\n",
    "        \"wandb tensorboard\",\n",
    "        \"accelerate deepspeed\",\n",
    "        \"timm albumentations\",\n",
    "        \"whisper-openai\",\n",
    "        \"diffusers\",\n",
    "        \"sentence-transformers\"\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "            print(f\"✓ Installed {package}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"✗ Failed to install {package}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu_setup():\n",
    "    \"\"\"Check GPU availability and configuration\"\"\"\n",
    "    print(\"=== GPU Setup Check ===\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    # Test basic tensor operations\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x = torch.randn(1000, 1000).to(device)\n",
    "    y = torch.mm(x, x.t())\n",
    "    print(f\"✓ Basic tensor operations working on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_libraries():\n",
    "    \"\"\"Test core libraries functionality\"\"\"\n",
    "    print(\"\\n=== Library Tests ===\")\n",
    "    \n",
    "    # Test transformers\n",
    "    try:\n",
    "        from transformers import AutoTokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        tokens = tokenizer(\"Hello world!\")\n",
    "        print(\"✓ Transformers library working\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Transformers error: {e}\")\n",
    "    \n",
    "    # Test computer vision\n",
    "    try:\n",
    "        import cv2\n",
    "        import torchvision.transforms as transforms\n",
    "        transform = transforms.Compose([transforms.Resize((224, 224))])\n",
    "        print(\"✓ Computer vision libraries working\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ CV libraries error: {e}\")\n",
    "    \n",
    "    # Test audio processing\n",
    "    try:\n",
    "        import librosa\n",
    "        print(\"✓ Audio processing libraries working\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Audio libraries error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_gpu_setup()\n",
    "test_libraries()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
