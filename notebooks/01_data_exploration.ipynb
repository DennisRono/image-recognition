{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b137742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetAnalyzer:\n",
    "    def __init__(self, data_root=\"./datasets\"):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.dataset_info = {}\n",
    "    \n",
    "    def analyze_image_dataset(self, dataset_path):\n",
    "        \"\"\"Analyze image dataset structure and statistics\"\"\"\n",
    "        path = self.data_root / dataset_path\n",
    "        if not path.exists():\n",
    "            print(f\"Dataset path {path} does not exist\")\n",
    "            return None\n",
    "        \n",
    "        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "        image_files = []\n",
    "        class_counts = Counter()\n",
    "        \n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if Path(file).suffix.lower() in image_extensions:\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "                    # Extract class from directory structure\n",
    "                    class_name = Path(root).name\n",
    "                    class_counts[class_name] += 1\n",
    "        \n",
    "        stats = {\n",
    "            'total_images': len(image_files),\n",
    "            'num_classes': len(class_counts),\n",
    "            'class_distribution': dict(class_counts),\n",
    "            'sample_files': image_files[:5]\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def analyze_text_dataset(self, dataset_path):\n",
    "        \"\"\"Analyze text corpus statistics\"\"\"\n",
    "        path = self.data_root / dataset_path\n",
    "        if not path.exists():\n",
    "            return None\n",
    "        \n",
    "        text_files = list(path.glob(\"*.txt\")) + list(path.glob(\"*.json\"))\n",
    "        total_chars = 0\n",
    "        total_words = 0\n",
    "        total_lines = 0\n",
    "        \n",
    "        for file_path in text_files[:10]:  # Sample first 10 files\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    total_chars += len(content)\n",
    "                    total_words += len(content.split())\n",
    "                    total_lines += len(content.split('\\n'))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "        \n",
    "        stats = {\n",
    "            'total_files': len(text_files),\n",
    "            'avg_chars_per_file': total_chars / max(len(text_files[:10]), 1),\n",
    "            'avg_words_per_file': total_words / max(len(text_files[:10]), 1),\n",
    "            'avg_lines_per_file': total_lines / max(len(text_files[:10]), 1),\n",
    "            'sample_files': [str(f) for f in text_files[:5]]\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def analyze_audio_dataset(self, dataset_path):\n",
    "        \"\"\"Analyze audio dataset statistics\"\"\"\n",
    "        path = self.data_root / dataset_path\n",
    "        if not path.exists():\n",
    "            return None\n",
    "        \n",
    "        audio_extensions = {'.wav', '.mp3', '.flac', '.m4a'}\n",
    "        audio_files = []\n",
    "        \n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if Path(file).suffix.lower() in audio_extensions:\n",
    "                    audio_files.append(os.path.join(root, file))\n",
    "        \n",
    "        # Sample analysis (would need librosa for detailed analysis)\n",
    "        stats = {\n",
    "            'total_audio_files': len(audio_files),\n",
    "            'sample_files': audio_files[:5],\n",
    "            'file_extensions': list(set(Path(f).suffix for f in audio_files))\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def analyze_video_dataset(self, dataset_path):\n",
    "        \"\"\"Analyze video dataset statistics\"\"\"\n",
    "        path = self.data_root / dataset_path\n",
    "        if not path.exists():\n",
    "            return None\n",
    "        \n",
    "        video_extensions = {'.mp4', '.avi', '.mov', '.mkv'}\n",
    "        video_files = []\n",
    "        \n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if Path(file).suffix.lower() in video_extensions:\n",
    "                    video_files.append(os.path.join(root, file))\n",
    "        \n",
    "        stats = {\n",
    "            'total_video_files': len(video_files),\n",
    "            'sample_files': video_files[:5],\n",
    "            'file_extensions': list(set(Path(f).suffix for f in video_files))\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def generate_overview_report(self):\n",
    "        \"\"\"Generate comprehensive dataset overview\"\"\"\n",
    "        datasets = {\n",
    "            'images': ['imagenet', 'coco', 'flickr30k'],\n",
    "            'text': ['wikipedia', 'books', 'news'],\n",
    "            'audio': ['librispeech', 'commonvoice', 'musiccaps'],\n",
    "            'video': ['kinetics', 'activitynet', 'msr_vtt']\n",
    "        }\n",
    "        \n",
    "        report = {'dataset_overview': {}}\n",
    "        \n",
    "        for modality, dataset_list in datasets.items():\n",
    "            report['dataset_overview'][modality] = {}\n",
    "            for dataset in dataset_list:\n",
    "                if modality == 'images':\n",
    "                    stats = self.analyze_image_dataset(dataset)\n",
    "                elif modality == 'text':\n",
    "                    stats = self.analyze_text_dataset(dataset)\n",
    "                elif modality == 'audio':\n",
    "                    stats = self.analyze_audio_dataset(dataset)\n",
    "                elif modality == 'video':\n",
    "                    stats = self.analyze_video_dataset(dataset)\n",
    "                \n",
    "                if stats:\n",
    "                    report['dataset_overview'][modality][dataset] = stats\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def visualize_dataset_stats(self, report):\n",
    "        \"\"\"Create visualizations of dataset statistics\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Dataset Overview Statistics', fontsize=16)\n",
    "        \n",
    "        # Image dataset class distribution\n",
    "        if 'images' in report['dataset_overview']:\n",
    "            ax = axes[0, 0]\n",
    "            for dataset, stats in report['dataset_overview']['images'].items():\n",
    "                if stats and 'class_distribution' in stats:\n",
    "                    classes = list(stats['class_distribution'].keys())[:10]\n",
    "                    counts = [stats['class_distribution'][c] for c in classes]\n",
    "                    ax.bar(range(len(classes)), counts, alpha=0.7, label=dataset)\n",
    "            ax.set_title('Image Dataset Class Distribution (Top 10)')\n",
    "            ax.set_xlabel('Classes')\n",
    "            ax.set_ylabel('Count')\n",
    "            ax.legend()\n",
    "        \n",
    "        # Text dataset file counts\n",
    "        if 'text' in report['dataset_overview']:\n",
    "            ax = axes[0, 1]\n",
    "            datasets = []\n",
    "            file_counts = []\n",
    "            for dataset, stats in report['dataset_overview']['text'].items():\n",
    "                if stats:\n",
    "                    datasets.append(dataset)\n",
    "                    file_counts.append(stats.get('total_files', 0))\n",
    "            ax.bar(datasets, file_counts, color='green', alpha=0.7)\n",
    "            ax.set_title('Text Dataset File Counts')\n",
    "            ax.set_ylabel('Number of Files')\n",
    "        \n",
    "        # Audio dataset statistics\n",
    "        if 'audio' in report['dataset_overview']:\n",
    "            ax = axes[1, 0]\n",
    "            datasets = []\n",
    "            audio_counts = []\n",
    "            for dataset, stats in report['dataset_overview']['audio'].items():\n",
    "                if stats:\n",
    "                    datasets.append(dataset)\n",
    "                    audio_counts.append(stats.get('total_audio_files', 0))\n",
    "            ax.bar(datasets, audio_counts, color='orange', alpha=0.7)\n",
    "            ax.set_title('Audio Dataset File Counts')\n",
    "            ax.set_ylabel('Number of Audio Files')\n",
    "        \n",
    "        # Video dataset statistics\n",
    "        if 'video' in report['dataset_overview']:\n",
    "            ax = axes[1, 1]\n",
    "            datasets = []\n",
    "            video_counts = []\n",
    "            for dataset, stats in report['dataset_overview']['video'].items():\n",
    "                if stats:\n",
    "                    datasets.append(dataset)\n",
    "                    video_counts.append(stats.get('total_video_files', 0))\n",
    "            ax.bar(datasets, video_counts, color='red', alpha=0.7)\n",
    "            ax.set_title('Video Dataset File Counts')\n",
    "            ax.set_ylabel('Number of Video Files')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d415ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    analyzer = DatasetAnalyzer()\n",
    "    \n",
    "    print(\"Generating Dataset Overview Report...\")\n",
    "    report = analyzer.generate_overview_report()\n",
    "    \n",
    "    # Save report\n",
    "    with open('dataset_overview_report.json', 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    print(\"Dataset Overview Report:\")\n",
    "    print(json.dumps(report, indent=2))\n",
    "    \n",
    "    # Create visualizations\n",
    "    analyzer.visualize_dataset_stats(report)\n",
    "    \n",
    "    print(\"\\nâœ“ Dataset overview analysis complete!\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
