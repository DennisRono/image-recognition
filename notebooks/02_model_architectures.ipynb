{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffafb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedImagePreprocessor:\n",
    "    def __init__(self, image_size=(384, 384)):\n",
    "        self.image_size = image_size\n",
    "        self.setup_transforms()\n",
    "    \n",
    "    def setup_transforms(self):\n",
    "        \"\"\"Setup various image transformation pipelines\"\"\"\n",
    "        \n",
    "        # Basic transforms\n",
    "        self.basic_transforms = transforms.Compose([\n",
    "            transforms.Resize(self.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Advanced augmentations using Albumentations\n",
    "        self.train_transforms = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.3),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.4),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3),\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "                A.MotionBlur(blur_limit=7, p=0.3),\n",
    "                A.MedianBlur(blur_limit=7, p=0.3)\n",
    "            ], p=0.2),\n",
    "            A.OneOf([\n",
    "                A.OpticalDistortion(distort_limit=0.1, p=0.3),\n",
    "                A.GridDistortion(distort_limit=0.1, p=0.3),\n",
    "                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3)\n",
    "            ], p=0.2),\n",
    "            A.CLAHE(clip_limit=3.0, tile_grid_size=(8, 8), p=0.2),\n",
    "            A.RandomShadow(p=0.1),\n",
    "            A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), p=0.1),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "        \n",
    "        # Validation transforms\n",
    "        self.val_transforms = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "        \n",
    "        # SAM preprocessing (for Segment Anything Model)\n",
    "        self.sam_transforms = A.Compose([\n",
    "            A.LongestMaxSize(max_size=1024),\n",
    "            A.PadIfNeeded(min_height=1024, min_width=1024, \n",
    "                         border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    def apply_mixup(self, images, labels, alpha=0.2):\n",
    "        \"\"\"Apply MixUp augmentation\"\"\"\n",
    "        if alpha > 0:\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "        else:\n",
    "            lam = 1\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        index = torch.randperm(batch_size)\n",
    "        \n",
    "        mixed_images = lam * images + (1 - lam) * images[index, :]\n",
    "        y_a, y_b = labels, labels[index]\n",
    "        \n",
    "        return mixed_images, y_a, y_b, lam\n",
    "    \n",
    "    def apply_cutmix(self, images, labels, alpha=1.0):\n",
    "        \"\"\"Apply CutMix augmentation\"\"\"\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        batch_size = images.size(0)\n",
    "        index = torch.randperm(batch_size)\n",
    "        \n",
    "        y_a, y_b = labels, labels[index]\n",
    "        bbx1, bby1, bbx2, bby2 = self.rand_bbox(images.size(), lam)\n",
    "        \n",
    "        images[:, :, bbx1:bbx2, bby1:bby2] = images[index, :, bbx1:bbx2, bby1:bby2]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))\n",
    "        \n",
    "        return images, y_a, y_b, lam\n",
    "    \n",
    "    def rand_bbox(self, size, lam):\n",
    "        \"\"\"Generate random bounding box for CutMix\"\"\"\n",
    "        W = size[2]\n",
    "        H = size[3]\n",
    "        cut_rat = np.sqrt(1. - lam)\n",
    "        cut_w = int(W * cut_rat)\n",
    "        cut_h = int(H * cut_rat)\n",
    "        \n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        \n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        \n",
    "        return bbx1, bby1, bbx2, bby2\n",
    "    \n",
    "    def generate_synthetic_data(self, num_samples=100):\n",
    "        \"\"\"Generate synthetic image data for testing\"\"\"\n",
    "        synthetic_images = []\n",
    "        synthetic_labels = []\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Create random colored rectangles\n",
    "            img = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
    "            \n",
    "            # Add some geometric shapes\n",
    "            cv2.rectangle(img, (50, 50), (150, 150), \n",
    "                         (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)), -1)\n",
    "            cv2.circle(img, (100, 100), 30, \n",
    "                      (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)), -1)\n",
    "            \n",
    "            synthetic_images.append(img)\n",
    "            synthetic_labels.append(i % 10)  # 10 classes\n",
    "        \n",
    "        return synthetic_images, synthetic_labels\n",
    "    \n",
    "    def visualize_augmentations(self, image_path=None):\n",
    "        \"\"\"Visualize different augmentation techniques\"\"\"\n",
    "        if image_path is None:\n",
    "            # Create a sample image\n",
    "            image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
    "            cv2.rectangle(image, (50, 50), (150, 150), (255, 0, 0), -1)\n",
    "            cv2.circle(image, (100, 100), 30, (0, 255, 0), -1)\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply different transformations\n",
    "        augmentations = [\n",
    "            (\"Original\", lambda x: x),\n",
    "            (\"Horizontal Flip\", A.HorizontalFlip(p=1.0)),\n",
    "            (\"Random Brightness\", A.RandomBrightnessContrast(brightness_limit=0.3, p=1.0)),\n",
    "            (\"Gaussian Blur\", A.GaussianBlur(blur_limit=(5, 5), p=1.0)),\n",
    "            (\"Rotation\", A.Rotate(limit=45, p=1.0)),\n",
    "            (\"Elastic Transform\", A.ElasticTransform(alpha=50, sigma=5, p=1.0))\n",
    "        ]\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, (name, aug) in enumerate(augmentations):\n",
    "            if callable(aug) and name != \"Original\":\n",
    "                augmented = aug(image=image)['image']\n",
    "            else:\n",
    "                augmented = image\n",
    "            \n",
    "            axes[i].imshow(augmented)\n",
    "            axes[i].set_title(name)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    preprocessor = AdvancedImagePreprocessor()\n",
    "    \n",
    "    print(\"Image Preprocessing Pipeline Initialized\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Generate synthetic data for demonstration\n",
    "    print(\"Generating synthetic image data...\")\n",
    "    images, labels = preprocessor.generate_synthetic_data(10)\n",
    "    print(f\"Generated {len(images)} synthetic images\")\n",
    "    \n",
    "    # Test transformations\n",
    "    print(\"\\nTesting image transformations...\")\n",
    "    sample_image = images[0]\n",
    "    \n",
    "    # Convert to PIL for torchvision transforms\n",
    "    pil_image = Image.fromarray(sample_image)\n",
    "    basic_transformed = preprocessor.basic_transforms(pil_image)\n",
    "    print(f\"Basic transform output shape: {basic_transformed.shape}\")\n",
    "    \n",
    "    # Test albumentations\n",
    "    train_transformed = preprocessor.train_transforms(image=sample_image)['image']\n",
    "    print(f\"Advanced transform output shape: {train_transformed.shape}\")\n",
    "    \n",
    "    # Visualize augmentations\n",
    "    print(\"\\nVisualizing augmentation techniques...\")\n",
    "    preprocessor.visualize_augmentations()\n",
    "    \n",
    "    # Test batch augmentations\n",
    "    print(\"\\nTesting batch augmentations...\")\n",
    "    batch_images = torch.randn(4, 3, 224, 224)\n",
    "    batch_labels = torch.tensor([0, 1, 2, 3])\n",
    "    \n",
    "    # MixUp\n",
    "    mixed_images, y_a, y_b, lam = preprocessor.apply_mixup(batch_images, batch_labels)\n",
    "    print(f\"MixUp - Lambda: {lam:.3f}, Output shape: {mixed_images.shape}\")\n",
    "    \n",
    "    # CutMix\n",
    "    cut_images, y_a, y_b, lam = preprocessor.apply_cutmix(batch_images, batch_labels)\n",
    "    print(f\"CutMix - Lambda: {lam:.3f}, Output shape: {cut_images.shape}\")\n",
    "    \n",
    "    print(\"\\n✓ Image preprocessing pipeline tested successfully!\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
